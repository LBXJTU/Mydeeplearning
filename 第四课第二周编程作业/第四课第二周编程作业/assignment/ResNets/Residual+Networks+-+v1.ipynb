{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Residual Networks\n",
    "\n",
    "Welcome to the second assignment of this week! You will learn how to build very deep convolutional networks, using Residual Networks (ResNets). In theory, very deep networks can represent very complex functions; but in practice, they are hard to train. Residual Networks, introduced by [He et al.](https://arxiv.org/pdf/1512.03385.pdf), allow you to train much deeper networks than were previously practically feasible.\n",
    "\n",
    "**In this assignment, you will:**\n",
    "- Implement the basic building blocks of ResNets. \n",
    "- Put together these building blocks to implement and train a state-of-the-art neural network for image classification. \n",
    "\n",
    "This assignment will be done in Keras. \n",
    "\n",
    "Before jumping into the problem, let's run the cell below to load the required packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras import layers\n",
    "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
    "from keras.models import Model, load_model\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import layer_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "import pydot\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils import plot_model\n",
    "from resnets_utils import *\n",
    "from keras.initializers import glorot_uniform\n",
    "import scipy.misc\n",
    "from matplotlib.pyplot import imshow\n",
    "%matplotlib inline\n",
    "\n",
    "import keras.backend as K\n",
    "K.set_image_data_format('channels_last')\n",
    "K.set_learning_phase(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - The problem of very deep neural networks\n",
    "\n",
    "Last week, you built your first convolutional neural network. In recent years, neural networks have become deeper, with state-of-the-art networks going from just a few layers (e.g., AlexNet) to over a hundred layers.\n",
    "\n",
    "The main benefit of a very deep network is that it can represent very complex functions. It can also learn features at many different levels of abstraction, from edges (at the lower layers) to very complex features (at the deeper layers). However, using a deeper network doesn't always help. A huge barrier to training them is vanishing gradients: very deep networks often have a gradient signal that goes to zero quickly, thus making gradient descent unbearably slow. More specifically, during gradient descent, as you backprop from the final layer back to the first layer, you are multiplying by the weight matrix on each step, and thus the gradient can decrease exponentially quickly to zero (or, in rare cases, grow exponentially quickly and \"explode\" to take very large values). 一个非常深的网络的主要好处是它可以代表非常复杂的功能。 它还可以学习许多不同抽象层次的特征，从边缘（较低层）到非常复杂的特征（较深层）。 但是，使用更深的网络并不总是有帮助。 训练它们的巨大障碍是梯度消失：非常深的网络通常会有一个梯度信号快速变为零，从而使梯度下降非常缓慢。 更具体地说，在梯度下降过程中，当您从最后一层返回到第一层时，您将乘以每一步的权重矩阵，因此梯度可以指数快速下降到零（或在极少数情况下，按指数级增长 快速并“爆炸”以获得非常大的值）。\n",
    "\n",
    "During training, you might therefore see the magnitude (or norm) of the gradient for the earlier layers descrease to zero very rapidly as training proceeds: 在训练期间，您可能会看到随着训练的进行，较早层的梯度幅度（或标准）会非常迅速地降至零：没有残差加入的时候，梯度在正向传播时候，很容易发生梯度消失 或者 爆炸，加入发生梯度消失的时候，误差在从最后一层往前传的过程中，梯度会迅速降到0？？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/vanishing_grad_kiank.png\" style=\"width:450px;height:220px;\">\n",
    "<caption><center> <u> <font color='purple'> **Figure 1** </u><font color='purple'>  : **Vanishing gradient** <br> The speed of learning decreases very rapidly for the early layers as the network trains </center></caption>\n",
    "\n",
    "You are now going to solve this problem by building a Residual Network!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Building a Residual Network\n",
    "\n",
    "In ResNets, a \"shortcut\" or a \"skip connection\" allows the gradient to be directly backpropagated to earlier layers: \n",
    "在残差网络中，能够是的梯度能够直接的逆传播到更早的网络层\n",
    "\n",
    "<img src=\"images/skip_connection_kiank.png\" style=\"width:650px;height:200px;\">\n",
    "<caption><center> <u> <font color='purple'> **Figure 2** </u><font color='purple'>  : A ResNet block showing a **skip-connection** <br> </center></caption>\n",
    "\n",
    "The image on the left shows the \"main path\" through the network. The image on the right adds a shortcut to the main path. By stacking these ResNet blocks on top of each other, you can form a very deep network. \n",
    "\n",
    "We also saw in lecture that having ResNet blocks with the shortcut also makes it very easy for one of the blocks to learn an identity function. This means that you can stack on additional ResNet blocks with little risk of harming training set performance. (There is also some evidence that the ease of learning an identity function--even more than skip connections helping with vanishing gradients--accounts for ResNets' remarkable performance.)\n",
    "\n",
    "Two main types of blocks are used in a ResNet, depending mainly on whether the input/output dimensions are same or different. You are going to implement both of them. \n",
    "左侧的图像显示了通过网络的“主要路径”。 右侧的图像为主路径添加了快捷方式。 通过将这些ResNet模块堆叠在一起，您可以形成一个非常深的网络。\n",
    "\n",
    "我们还在演讲中看到，使用快捷方式的ResNet块也使得其中一个块非常容易学习识别功能。 这意味着您可以在其他ResNet模块上堆叠，而且几乎不会损害训练集性能。 （还有一些证据表明，学习身份函数的方便性 - 甚至比跳过渐变消失的连接更能说明ResNets的卓越表现。）\n",
    "\n",
    "ResNet使用两种主要类型的块，主要取决于输入/输出尺寸是相同还是不同。 你将要实现他们两个。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 - The identity block\n",
    "\n",
    "The identity block is the standard block used in ResNets, and corresponds to the case where the input activation (say $a^{[l]}$) has the same dimension as the output activation (say $a^{[l+2]}$). To flesh out the different steps of what happens in a ResNet's identity block, here is an alternative diagram showing the individual steps: $a^{[l]}$ 和$a^{[l+2]}$ 有相同的维度\n",
    "\n",
    "<img src=\"images/idblock2_kiank.png\" style=\"width:650px;height:150px;\">\n",
    "<caption><center> <u> <font color='purple'> **Figure 3** </u><font color='purple'>  : **Identity block.** Skip connection \"skips over\" 2 layers. </center></caption>\n",
    "\n",
    "The upper path is the \"shortcut path.\" The lower path is the \"main path.\" In this diagram, we have also made explicit the CONV2D and ReLU steps in each layer. To speed up training we have also added a BatchNorm step. Don't worry about this being complicated to implement--you'll see that BatchNorm is just one line of code in Keras!\n",
    "中的CONV2D和ReLU步骤。 为了加快培训，我们还添加了一个BatchNorm步骤。 不要担心实现起来很复杂 - 你会发现BatchNorm只是Keras中的一行代码！\n",
    "\n",
    "在本练习中，您将实际实现此身份块的稍微更强大的版本，其中跳过连接“跳过”3个隐藏层而不是2层。 它看起来像这样：\n",
    "\n",
    "In this exercise, you'll actually implement a slightly more powerful version of this identity block, in which the skip connection \"skips over\" 3 hidden layers rather than 2 layers. It looks like this: \n",
    "\n",
    "<img src=\"images/idblock3_kiank.png\" style=\"width:650px;height:150px;\">\n",
    "<caption><center> <u> <font color='purple'> **Figure 4** </u><font color='purple'>  : **Identity block.** Skip connection \"skips over\" 3 layers.</center></caption>\n",
    "\n",
    "Here're the individual steps.\n",
    "\n",
    "\n",
    "First component of main path: \n",
    "- The first CONV2D has $F_1$ filters of shape (1,1) and a stride of (1,1). Its padding is \"valid\" and its name should be `conv_name_base + '2a'`. Use 0 as the seed for the random initialization. \n",
    "- The first BatchNorm is normalizing the channels axis.  Its name should be `bn_name_base + '2a'`.\n",
    "- Then apply the ReLU activation function. This has no name and no hyperparameters. \n",
    "第一个CONV2D具有形状（1,1）的F1F1滤波器和（1,1）的步幅。 它的填充是“有效的”，它的名字应该是conv_name_base +'2a'。 使用0作为随机初始化的种子。\n",
    "第一个BatchNorm正在规范通道轴。 它的名字应该是bn_name_base +'2a'。\n",
    "然后应用ReLU激活功能。 这没有名字，也没有超参数。\n",
    "\n",
    "Second component of main path:\n",
    "- The second CONV2D has $F_2$ filters of shape $(f,f)$ and a stride of (1,1). Its padding is \"same\" and its name should be `conv_name_base + '2b'`. Use 0 as the seed for the random initialization. \n",
    "- The second BatchNorm is normalizing the channels axis.  Its name should be `bn_name_base + '2b'`.\n",
    "- Then apply the ReLU activation function. This has no name and no hyperparameters. \n",
    "\n",
    "Third component of main path:\n",
    "- The third CONV2D has $F_3$ filters of shape (1,1) and a stride of (1,1). Its padding is \"valid\" and its name should be `conv_name_base + '2c'`. Use 0 as the seed for the random initialization. \n",
    "- The third BatchNorm is normalizing the channels axis.  Its name should be `bn_name_base + '2c'`. Note that there is no ReLU activation function in this component. \n",
    "\n",
    "Final step: \n",
    "- The shortcut and the input are added together. 注意 上面的图 整个是一个残差块，他最后将输入和残差的数输出加起来，然后在激活函数\n",
    "- Then apply the ReLU activation function. This has no name and no hyperparameters. \n",
    "\n",
    "**Exercise**: Implement the ResNet identity block. We have implemented the first component of the main path. Please read over this carefully to make sure you understand what it is doing. You should implement the rest. \n",
    "- To implement the Conv2D step: [See reference](https://keras.io/layers/convolutional/#conv2d)\n",
    "- To implement BatchNorm: [See reference](https://faroit.github.io/keras-docs/1.2.2/layers/normalization/) (axis: Integer, the axis that should be normalized (typically the channels axis))\n",
    "- For the activation, use:  `Activation('relu')(X)`\n",
    "- To add the value passed forward by the shortcut: [See reference](https://keras.io/layers/merge/#add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: identity_block\n",
    "#输入和输出的 X的尺寸是一样的\n",
    "\n",
    "def identity_block(X, f, filters, stage, block):\n",
    "    \"\"\"\n",
    "    Implementation of the identity block as defined in Figure 4\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
    "    f -- integer, specifying the shape of the middle CONV's window for the main path 整数，指定主路径的中间CONV窗口的形状\n",
    "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
    "               定义了各个卷基层的 过滤器的个数\n",
    "    \n",
    "    stage -- integer, used to name the layers, depending on their position in the network\n",
    "             整数，用于命名层，这取决于它们的位置在网络中的\n",
    "    block -- string/character, used to name the layers, depending on their position in the network\n",
    "             字符串和字符，用来命名神经层，取决于他们在网络中的位置\n",
    "    Returns:\n",
    "    X -- output of the identity block, tensor of shape (n_H, n_W, n_C)\n",
    "    \"\"\"\n",
    "    \n",
    "    # defining name basis\n",
    "    #用来命名，例如：第几个残差块 \n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "    \n",
    "    # Retrieve Filters \n",
    "    F1, F2, F3 = filters\n",
    "    #卷积核大小为1*1的 只是将3个通道的 累积和 加起来了 ，并没有改变原来图片的大小\n",
    "    \n",
    "    # Save the input value. You'll need this later to add back to the main path. 输入值，你需要将它放入加入到后面的残差块\n",
    "    X_shortcut = X\n",
    "    print(str(X))\n",
    "    # First component of main path\n",
    "    X = Conv2D(filters = F1, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2a', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    print(\"第一个卷积层有：\" + str(F1) +\"块卷积核\")\n",
    "    print(\"经过卷积核X的结果 ：\" + str(X.shape))\n",
    "    print(str(X))\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
    "    print(\"经过BatchNormalization的结果 ：\" + str(X))\n",
    "    print(str(X))\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    \n",
    "    # Second component of main path (≈3 lines)\n",
    "    X = Conv2D(filters = F2, kernel_size = (f, f), strides = (1,1), padding = 'same', name = conv_name_base + '2b', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    print(str(X))\n",
    "    X = BatchNormalization(axis=3, name = bn_name_base + '2b')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # Third component of main path (≈2 lines)\n",
    "    X = Conv2D(filters = F3, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2c', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    print(str(X))\n",
    "    X = BatchNormalization(axis=3, name = bn_name_base + '2c')(X)\n",
    "\n",
    "    # Final step: Add shortcut value to main path, and pass it through a RELU activation (≈2 lines)\n",
    "    X = layers.add([X, X_shortcut])\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Placeholder:0\", shape=(3, 4, 4, 6), dtype=float32)\n",
      "Tensor(\"Placeholder:0\", shape=(3, 4, 4, 6), dtype=float32)\n",
      "第一个卷积层有：2块卷积核\n",
      "经过卷积核X的结果 ：(3, 4, 4, 2)\n",
      "Tensor(\"res1a_branch2a/BiasAdd:0\", shape=(3, 4, 4, 2), dtype=float32)\n",
      "经过BatchNormalization的结果 ：Tensor(\"bn1a_branch2a/cond/Merge:0\", shape=(3, 4, 4, 2), dtype=float32)\n",
      "Tensor(\"bn1a_branch2a/cond/Merge:0\", shape=(3, 4, 4, 2), dtype=float32)\n",
      "Tensor(\"res1a_branch2b/BiasAdd:0\", shape=(3, 4, 4, 4), dtype=float32)\n",
      "Tensor(\"res1a_branch2c/BiasAdd:0\", shape=(3, 4, 4, 6), dtype=float32)\n",
      "out = [0.94822985 0.         1.1610144  2.747859   0.         1.36677   ]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.Session() as test:\n",
    "    np.random.seed(1)\n",
    "    #X = Tensor(\"X:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
    "    A_prev = tf.placeholder(\"float\", [3, 4, 4, 6])\n",
    "    print(str(A_prev))\n",
    "    X = np.random.randn(3, 4, 4, 6)\n",
    "    #print(str(X)) #输出的是所有x的矩阵的值\n",
    "    A = identity_block(A_prev, f = 2, filters = [2, 4, 6], stage = 1, block = 'a')\n",
    "    test.run(tf.global_variables_initializer())\n",
    "    out = test.run([A], feed_dict={A_prev: X, K.learning_phase(): 0})\n",
    "    print(\"out = \" + str(out[0][1][1][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**:\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            **out**\n",
    "        </td>\n",
    "        <td>\n",
    "           [ 0.94822985  0.          1.16101444  2.747859    0.          1.36677003]\n",
    "        </td>\n",
    "    </tr>\n",
    "\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 - The convolutional block\n",
    "\n",
    "You've implemented the ResNet identity block. Next, the ResNet \"convolutional block\" is the other type of block. You can use this type of block when the input and output dimensions don't match up. The difference with the identity block is that there is a CONV2D layer in the shortcut path: 输入和输出的X尺寸是不一样的，所以上面的路径需要改变一下他的维度\n",
    "\n",
    "<img src=\"images/convblock_kiank.png\" style=\"width:650px;height:150px;\">\n",
    "<caption><center> <u> <font color='purple'> **Figure 4** </u><font color='purple'>  : **Convolutional block** </center></caption>\n",
    "\n",
    "The CONV2D layer in the shortcut path is used to resize the input $x$ to a different dimension, so that the dimensions match up in the final addition needed to add the shortcut value back to the main path. (This plays a similar role as the matrix $W_s$ discussed in lecture.) 输入和输出的维度不一样，所以需要进行一下维度调整 For example, to reduce the activation dimensions's height and width by a factor of 2, you can use a 1x1 convolution with a stride of 2. The CONV2D layer on the shortcut path does not use any non-linear activation function. Its main role is to just apply a (learned) linear function that reduces the dimension of the input, so that the dimensions match up for the later addition step. \n",
    "快捷方式路径中的CONV2D图层用于将输入xx调整为不同的尺寸，以便在添加快捷方式值到主路径时需要的最终添加中匹配尺寸。 （这与演讲中讨论的矩阵WsW类似）。例如，要将激活维度的高度和宽度缩小2倍，可以使用步长为2的1x1卷积。快捷方式上的CONV2D图层 路径不使用任何非线性激活函数。 它的主要作用是仅应用一个（学习）线性函数来减小输入的尺寸，以便尺寸匹配后面的加法步骤。\n",
    "\n",
    "The details of the convolutional block are as follows. \n",
    "\n",
    "First component of main path:\n",
    "- The first CONV2D has $F_1$ filters of shape (1,1) and a stride of (s,s). Its padding is \"valid\" and its name should be `conv_name_base + '2a'`. \n",
    "- The first BatchNorm is normalizing the channels axis.  Its name should be `bn_name_base + '2a'`.\n",
    "- Then apply the ReLU activation function. This has no name and no hyperparameters. \n",
    "\n",
    "Second component of main path:\n",
    "- The second CONV2D has $F_2$ filters of (f,f) and a stride of (1,1). Its padding is \"same\" and it's name should be `conv_name_base + '2b'`.\n",
    "- The second BatchNorm is normalizing the channels axis.  Its name should be `bn_name_base + '2b'`.\n",
    "- Then apply the ReLU activation function. This has no name and no hyperparameters. \n",
    "\n",
    "Third component of main path:\n",
    "- The third CONV2D has $F_3$ filters of (1,1) and a stride of (1,1). Its padding is \"valid\" and it's name should be `conv_name_base + '2c'`.\n",
    "- The third BatchNorm is normalizing the channels axis.  Its name should be `bn_name_base + '2c'`. Note that there is no ReLU activation function in this component. \n",
    "\n",
    "Shortcut path:\n",
    "- The CONV2D has $F_3$ filters of shape (1,1) and a stride of (s,s). Its padding is \"valid\" and its name should be `conv_name_base + '1'`.\n",
    "- The BatchNorm is normalizing the channels axis.  Its name should be `bn_name_base + '1'`. \n",
    "\n",
    "Final step: \n",
    "- The shortcut and the main path values are added together.\n",
    "- Then apply the ReLU activation function. This has no name and no hyperparameters. \n",
    "    \n",
    "**Exercise**: Implement the convolutional block. We have implemented the first component of the main path; you should implement the rest. As before, always use 0 as the seed for the random initialization, to ensure consistency with our grader.\n",
    "- [Conv Hint](https://keras.io/layers/convolutional/#conv2d)\n",
    "- [BatchNorm Hint](https://keras.io/layers/normalization/#batchnormalization) (axis: Integer, the axis that should be normalized (typically the features axis))\n",
    "- For the activation, use:  `Activation('relu')(X)`\n",
    "- [Addition Hint](https://keras.io/layers/merge/#add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: convolutional_block\n",
    "\n",
    "def convolutional_block(X, f, filters, stage, block, s = 2):\n",
    "    \"\"\"\n",
    "    Implementation of the convolutional block as defined in Figure 4\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
    "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
    "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
    "    stage -- integer, used to name the layers, depending on their position in the network\n",
    "    block -- string/character, used to name the layers, depending on their position in the network\n",
    "    s -- Integer, specifying the stride to be used\n",
    "    \n",
    "    Returns:\n",
    "    X -- output of the convolutional block, tensor of shape (n_H, n_W, n_C)\n",
    "    \"\"\"\n",
    "    \n",
    "    # defining name basis\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "    \n",
    "    # Retrieve Filters\n",
    "    F1, F2, F3 = filters\n",
    "    \n",
    "    # Save the input value\n",
    "    X_shortcut = X\n",
    "\n",
    "    print(\"没有经过卷积操作的 X的维度 \" + str(X))\n",
    "    ##### MAIN PATH #####\n",
    "    # First component of main path \n",
    "    X = Conv2D(F1, (1, 1), strides = (s,s), name = conv_name_base + '2a', padding='valid', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    print(\"经过一次卷积 主路径第一步的维度 \"+ str(X))\n",
    "    ### START CODE HERE ###\n",
    "\n",
    "    # Second component of main path (≈3 lines)\n",
    "    X = Conv2D(F2, (f, f), strides = (1, 1), name = conv_name_base + '2b',padding='same', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    print(\"经过第二次卷积 主路径第二步的维度 \"+ str(X))\n",
    "    \n",
    "    # Third component of main path (≈2 lines)\n",
    "    X = Conv2D(F3, (1, 1), strides = (1, 1), name = conv_name_base + '2c',padding='valid', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n",
    "    print(\"经过第三次卷积 主路径的第三步的维度为 \" + str(X))\n",
    "    \n",
    "    ##### SHORTCUT PATH #### (≈2 lines)\n",
    "    X_shortcut = Conv2D(F3, (1, 1), strides = (s, s), name = conv_name_base + '1',padding='valid', kernel_initializer = glorot_uniform(seed=0))(X_shortcut)\n",
    "    X_shortcut = BatchNormalization(axis = 3, name = bn_name_base + '1')(X_shortcut)\n",
    "    print(\"上面路径的卷积的维度 \" + str(X_shortcut))\n",
    "    # Final step: Add shortcut value to main path, and pass it through a RELU activation (≈2 lines)\n",
    "    X = layers.add([X, X_shortcut])\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "没有经过卷积操作的 X的维度 Tensor(\"Placeholder:0\", shape=(3, 4, 4, 6), dtype=float32)\n",
      "经过一次卷积 主路径第一步的维度 Tensor(\"activation_1/Relu:0\", shape=(3, 2, 2, 2), dtype=float32)\n",
      "经过第二次卷积 主路径第二步的维度 Tensor(\"activation_2/Relu:0\", shape=(3, 2, 2, 4), dtype=float32)\n",
      "经过第三次卷积 主路径的第三步的维度为 Tensor(\"bn1a_branch2c/cond/Merge:0\", shape=(3, 2, 2, 6), dtype=float32)\n",
      "上面路径的卷积的维度 Tensor(\"bn1a_branch1/cond/Merge:0\", shape=(3, 2, 2, 6), dtype=float32)\n",
      "out = [0.09018463 1.2348977  0.46822017 0.0367176  0.         0.65516603]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.Session() as test:\n",
    "    np.random.seed(1)\n",
    "    A_prev = tf.placeholder(\"float\", [3, 4, 4, 6])\n",
    "    X = np.random.randn(3, 4, 4, 6)\n",
    "    A = convolutional_block(A_prev, f = 2, filters = [2, 4, 6], stage = 1, block = 'a')\n",
    "    test.run(tf.global_variables_initializer())\n",
    "    out = test.run([A], feed_dict={A_prev: X, K.learning_phase(): 0})\n",
    "    print(\"out = \" + str(out[0][1][1][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**:\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            **out**\n",
    "        </td>\n",
    "        <td>\n",
    "           [ 0.09018463  1.23489773  0.46822017  0.0367176   0.          0.65516603]\n",
    "        </td>\n",
    "    </tr>\n",
    "\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Building your first ResNet model (50 layers)\n",
    "\n",
    "You now have the necessary blocks to build a very deep ResNet. The following figure describes in detail the architecture of this neural network. \"ID BLOCK\" in the diagram stands for \"Identity block,\" and \"ID BLOCK x3\" means you should stack 3 identity blocks together. Identity block 代表的是 一致残差块 \n",
    "\n",
    "<img src=\"images/resnet_kiank.png\" style=\"width:850px;height:150px;\">\n",
    "<caption><center> <u> <font color='purple'> **Figure 5** </u><font color='purple'>  : **ResNet-50 model** </center></caption>\n",
    "\n",
    "The details of this ResNet-50 model are:\n",
    "- Zero-padding pads the input with a pad of (3,3)\n",
    "- Stage 1:\n",
    "    - The 2D Convolution has 64 filters of shape (7,7) and uses a stride of (2,2). Its name is \"conv1\".\n",
    "    - BatchNorm is applied to the channels axis of the input.\n",
    "    - MaxPooling uses a (3,3) window and a (2,2) stride.\n",
    "- Stage 2: [64,64,256] 代表的意思是 要经过3个卷积层，第一个卷积层是64个过滤器，第二个卷积层是64个过滤器，第三个是256个过滤器\n",
    "    - The convolutional block uses three set of filters of size [64,64,256], \"f\" is 3, \"s\" is 1 and the block is \"a\".\n",
    "    - The 2 identity blocks use three set of filters of size [64,64,256], \"f\" is 3 and the blocks are \"b\" and \"c\".\n",
    "- Stage 3:\n",
    "    - The convolutional block uses three set of filters of size [128,128,512], \"f\" is 3, \"s\" is 2 and the block is \"a\".\n",
    "    - The 3 identity blocks use three set of filters of size [128,128,512], \"f\" is 3 and the blocks are \"b\", \"c\" and \"d\". \n",
    "- Stage 4:\n",
    "    - The convolutional block uses three set of filters of size [256, 256, 1024], \"f\" is 3, \"s\" is 2 and the block is \"a\".\n",
    "    - The 5 identity blocks use three set of filters of size [256, 256, 1024], \"f\" is 3 and the blocks are \"b\", \"c\", \"d\", \"e\" and \"f\".\n",
    "- Stage 5:\n",
    "    - The convolutional block uses three set of filters of size [512, 512, 2048], \"f\" is 3, \"s\" is 2 and the block is \"a\".\n",
    "    - The 2 identity blocks use three set of filters of size [256, 256, 2048], \"f\" is 3 and the blocks are \"b\" and \"c\".\n",
    "- The 2D Average Pooling uses a window of shape (2,2) and its name is \"avg_pool\".\n",
    "- The flatten doesn't have any hyperparameters or name.\n",
    "- The Fully Connected (Dense) layer reduces its input to the number of classes using a softmax activation. Its name should be `'fc' + str(classes)`.\n",
    "\n",
    "**Exercise**: Implement the ResNet with 50 layers described in the figure above. We have implemented Stages 1 and 2. Please implement the rest. (The syntax for implementing Stages 3-5 should be quite similar to that of Stage 2.) Make sure you follow the naming convention in the text above. \n",
    "\n",
    "You'll need to use this function: \n",
    "- Average pooling [see reference](https://keras.io/layers/pooling/#averagepooling2d)\n",
    "\n",
    "Here're some other functions we used in the code below:\n",
    "- Conv2D: [See reference](https://keras.io/layers/convolutional/#conv2d)\n",
    "- BatchNorm: [See reference](https://keras.io/layers/normalization/#batchnormalization) (axis: Integer, the axis that should be normalized (typically the features axis))\n",
    "- Zero padding: [See reference](https://keras.io/layers/convolutional/#zeropadding2d)\n",
    "- Max pooling: [See reference](https://keras.io/layers/pooling/#maxpooling2d)\n",
    "- Fully conected layer: [See reference](https://keras.io/layers/core/#dense)\n",
    "- Addition: [See reference](https://keras.io/layers/merge/#add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: ResNet50\n",
    "\n",
    "def ResNet50(input_shape = (64, 64, 3), classes = 6):\n",
    "    \"\"\"\n",
    "    Implementation of the popular ResNet50 the following architecture:\n",
    "    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\n",
    "    -> CONVBLOCK -> IDBLOCK*5 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> TOPLAYER\n",
    "\n",
    "    Arguments:\n",
    "    input_shape -- shape of the images of the dataset\n",
    "    classes -- integer, number of classes\n",
    "\n",
    "    Returns:\n",
    "    model -- a Model() instance in Keras\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define the input as a tensor with shape input_shape\n",
    "    X_input = Input(input_shape)\n",
    "    print(\"X传入进来的维度： \"+ str(X_input))\n",
    "    \n",
    "    # Zero-Padding\n",
    "    X = ZeroPadding2D((3, 3))(X_input)\n",
    "    print(\"X padding之后的维度： \"+str(X))\n",
    "    \n",
    "    # Stage 1\n",
    "    X = Conv2D(64, (7, 7), strides = (2, 2), name = 'conv1', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = 'bn_conv1')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
    "\n",
    "    # Stage 2\n",
    "    X = convolutional_block(X, f = 3, filters = [64, 64, 256], stage = 2, block='a', s = 1)\n",
    "    print(\"X 经过stage2 之后 应该是 256个通道\" + str(X))\n",
    "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='b')\n",
    "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='c')\n",
    "\n",
    "    ### START CODE HERE ###\n",
    "\n",
    "    # Stage 3 (≈4 lines)\n",
    "    # The convolutional block uses three set of filters of size [128,128,512], \"f\" is 3, \"s\" is 2 and the block is \"a\".\n",
    "    # The 3 identity blocks use three set of filters of size [128,128,512], \"f\" is 3 and the blocks are \"b\", \"c\" and \"d\".\n",
    "    X = convolutional_block(X, f = 3, filters=[128,128,512], stage = 3, block='a', s = 2)\n",
    "    X = identity_block(X, f = 3, filters=[128,128,512], stage= 3, block='b')\n",
    "    X = identity_block(X, f = 3, filters=[128,128,512], stage= 3, block='c')\n",
    "    X = identity_block(X, f = 3, filters=[128,128,512], stage= 3, block='d')\n",
    "    print(\"X 经过stage3  之后 应该是 512个通道\" + str(X))\n",
    "\n",
    "    # Stage 4 (≈6 lines)\n",
    "    # The convolutional block uses three set of filters of size [256, 256, 1024], \"f\" is 3, \"s\" is 2 and the block is \"a\".\n",
    "    # The 5 identity blocks use three set of filters of size [256, 256, 1024], \"f\" is 3 and the blocks are \"b\", \"c\", \"d\", \"e\" and \"f\".\n",
    "    X = convolutional_block(X, f = 3, filters=[256, 256, 1024], block='a', stage=4, s = 2)\n",
    "    X = identity_block(X, f = 3, filters=[256, 256, 1024], block='b', stage=4)\n",
    "    X = identity_block(X, f = 3, filters=[256, 256, 1024], block='c', stage=4)\n",
    "    X = identity_block(X, f = 3, filters=[256, 256, 1024], block='d', stage=4)\n",
    "    X = identity_block(X, f = 3, filters=[256, 256, 1024], block='e', stage=4)\n",
    "    X = identity_block(X, f = 3, filters=[256, 256, 1024], block='f', stage=4)\n",
    "    print(\"X 经过stage4 之后 应该是 1024个通道\"+ str(X))\n",
    "\n",
    "    # Stage 5 (≈3 lines)\n",
    "    # The convolutional block uses three set of filters of size [512, 512, 2048], \"f\" is 3, \"s\" is 2 and the block is \"a\".\n",
    "    # The 2 identity blocks use three set of filters of size [256, 256, 2048], \"f\" is 3 and the blocks are \"b\" and \"c\".\n",
    "    X = convolutional_block(X, f = 3, filters=[512, 512, 2048], stage=5, block='a', s = 2)\n",
    "    \n",
    "    # filters should be [256, 256, 2048], but it fail to be graded. Use [512, 512, 2048] to pass the grading\n",
    "    X = identity_block(X, f = 3, filters=[256, 256, 2048], stage=5, block='b')\n",
    "    X = identity_block(X, f = 3, filters=[256, 256, 2048], stage=5, block='c')\n",
    "    print(\"X 经过stage5  之后 应该是 2048个通道\"+ str(X))\n",
    "    # AVGPOOL (≈1 line). Use \"X = AveragePooling2D(...)(X)\"\n",
    "    # The 2D Average Pooling uses a window of shape (2,2) and its name is \"avg_pool\".\n",
    "    X = AveragePooling2D(pool_size=(2,2))(X)\n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    # output layer\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(classes, activation='softmax', name='fc' + str(classes), kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    \n",
    "    \n",
    "    # Create model\n",
    "    model = Model(inputs = X_input, outputs = X, name='ResNet50')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following code to build the model's graph. If your implementation is not correct you will know it by checking your accuracy when running `model.fit(...)` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X传入进来的维度： Tensor(\"input_1:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "X padding之后的维度： Tensor(\"zero_padding2d_1/Pad:0\", shape=(?, 70, 70, 3), dtype=float32)\n",
      "没有经过卷积操作的 X的维度 Tensor(\"max_pooling2d_1/MaxPool:0\", shape=(?, 15, 15, 64), dtype=float32)\n",
      "经过一次卷积 主路径第一步的维度 Tensor(\"activation_5/Relu:0\", shape=(?, 15, 15, 64), dtype=float32)\n",
      "经过第二次卷积 主路径第二步的维度 Tensor(\"activation_6/Relu:0\", shape=(?, 15, 15, 64), dtype=float32)\n",
      "经过第三次卷积 主路径的第三步的维度为 Tensor(\"bn2a_branch2c/cond/Merge:0\", shape=(?, 15, 15, 256), dtype=float32)\n",
      "上面路径的卷积的维度 Tensor(\"bn2a_branch1/cond/Merge:0\", shape=(?, 15, 15, 256), dtype=float32)\n",
      "X 经过stage2 之后 应该是 256个通道Tensor(\"activation_7/Relu:0\", shape=(?, 15, 15, 256), dtype=float32)\n",
      "Tensor(\"activation_7/Relu:0\", shape=(?, 15, 15, 256), dtype=float32)\n",
      "第一个卷积层有：64块卷积核\n",
      "经过卷积核X的结果 ：(?, 15, 15, 64)\n",
      "Tensor(\"res2b_branch2a/BiasAdd:0\", shape=(?, 15, 15, 64), dtype=float32)\n",
      "经过BatchNormalization的结果 ：Tensor(\"bn2b_branch2a/cond/Merge:0\", shape=(?, 15, 15, 64), dtype=float32)\n",
      "Tensor(\"bn2b_branch2a/cond/Merge:0\", shape=(?, 15, 15, 64), dtype=float32)\n",
      "Tensor(\"res2b_branch2b/BiasAdd:0\", shape=(?, 15, 15, 64), dtype=float32)\n",
      "Tensor(\"res2b_branch2c/BiasAdd:0\", shape=(?, 15, 15, 256), dtype=float32)\n",
      "Tensor(\"activation_10/Relu:0\", shape=(?, 15, 15, 256), dtype=float32)\n",
      "第一个卷积层有：64块卷积核\n",
      "经过卷积核X的结果 ：(?, 15, 15, 64)\n",
      "Tensor(\"res2c_branch2a/BiasAdd:0\", shape=(?, 15, 15, 64), dtype=float32)\n",
      "经过BatchNormalization的结果 ：Tensor(\"bn2c_branch2a/cond/Merge:0\", shape=(?, 15, 15, 64), dtype=float32)\n",
      "Tensor(\"bn2c_branch2a/cond/Merge:0\", shape=(?, 15, 15, 64), dtype=float32)\n",
      "Tensor(\"res2c_branch2b/BiasAdd:0\", shape=(?, 15, 15, 64), dtype=float32)\n",
      "Tensor(\"res2c_branch2c/BiasAdd:0\", shape=(?, 15, 15, 256), dtype=float32)\n",
      "没有经过卷积操作的 X的维度 Tensor(\"activation_13/Relu:0\", shape=(?, 15, 15, 256), dtype=float32)\n",
      "经过一次卷积 主路径第一步的维度 Tensor(\"activation_14/Relu:0\", shape=(?, 8, 8, 128), dtype=float32)\n",
      "经过第二次卷积 主路径第二步的维度 Tensor(\"activation_15/Relu:0\", shape=(?, 8, 8, 128), dtype=float32)\n",
      "经过第三次卷积 主路径的第三步的维度为 Tensor(\"bn3a_branch2c/cond/Merge:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "上面路径的卷积的维度 Tensor(\"bn3a_branch1/cond/Merge:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "Tensor(\"activation_16/Relu:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "第一个卷积层有：128块卷积核\n",
      "经过卷积核X的结果 ：(?, 8, 8, 128)\n",
      "Tensor(\"res3b_branch2a/BiasAdd:0\", shape=(?, 8, 8, 128), dtype=float32)\n",
      "经过BatchNormalization的结果 ：Tensor(\"bn3b_branch2a/cond/Merge:0\", shape=(?, 8, 8, 128), dtype=float32)\n",
      "Tensor(\"bn3b_branch2a/cond/Merge:0\", shape=(?, 8, 8, 128), dtype=float32)\n",
      "Tensor(\"res3b_branch2b/BiasAdd:0\", shape=(?, 8, 8, 128), dtype=float32)\n",
      "Tensor(\"res3b_branch2c/BiasAdd:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "Tensor(\"activation_19/Relu:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "第一个卷积层有：128块卷积核\n",
      "经过卷积核X的结果 ：(?, 8, 8, 128)\n",
      "Tensor(\"res3c_branch2a/BiasAdd:0\", shape=(?, 8, 8, 128), dtype=float32)\n",
      "经过BatchNormalization的结果 ：Tensor(\"bn3c_branch2a/cond/Merge:0\", shape=(?, 8, 8, 128), dtype=float32)\n",
      "Tensor(\"bn3c_branch2a/cond/Merge:0\", shape=(?, 8, 8, 128), dtype=float32)\n",
      "Tensor(\"res3c_branch2b/BiasAdd:0\", shape=(?, 8, 8, 128), dtype=float32)\n",
      "Tensor(\"res3c_branch2c/BiasAdd:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "Tensor(\"activation_22/Relu:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "第一个卷积层有：128块卷积核\n",
      "经过卷积核X的结果 ：(?, 8, 8, 128)\n",
      "Tensor(\"res3d_branch2a/BiasAdd:0\", shape=(?, 8, 8, 128), dtype=float32)\n",
      "经过BatchNormalization的结果 ：Tensor(\"bn3d_branch2a/cond/Merge:0\", shape=(?, 8, 8, 128), dtype=float32)\n",
      "Tensor(\"bn3d_branch2a/cond/Merge:0\", shape=(?, 8, 8, 128), dtype=float32)\n",
      "Tensor(\"res3d_branch2b/BiasAdd:0\", shape=(?, 8, 8, 128), dtype=float32)\n",
      "Tensor(\"res3d_branch2c/BiasAdd:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "X 经过stage3  之后 应该是 512个通道Tensor(\"activation_25/Relu:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "没有经过卷积操作的 X的维度 Tensor(\"activation_25/Relu:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
      "经过一次卷积 主路径第一步的维度 Tensor(\"activation_26/Relu:0\", shape=(?, 4, 4, 256), dtype=float32)\n",
      "经过第二次卷积 主路径第二步的维度 Tensor(\"activation_27/Relu:0\", shape=(?, 4, 4, 256), dtype=float32)\n",
      "经过第三次卷积 主路径的第三步的维度为 Tensor(\"bn4a_branch2c/cond/Merge:0\", shape=(?, 4, 4, 1024), dtype=float32)\n",
      "上面路径的卷积的维度 Tensor(\"bn4a_branch1/cond/Merge:0\", shape=(?, 4, 4, 1024), dtype=float32)\n",
      "Tensor(\"activation_28/Relu:0\", shape=(?, 4, 4, 1024), dtype=float32)\n",
      "第一个卷积层有：256块卷积核\n",
      "经过卷积核X的结果 ：(?, 4, 4, 256)\n",
      "Tensor(\"res4b_branch2a/BiasAdd:0\", shape=(?, 4, 4, 256), dtype=float32)\n",
      "经过BatchNormalization的结果 ：Tensor(\"bn4b_branch2a/cond/Merge:0\", shape=(?, 4, 4, 256), dtype=float32)\n",
      "Tensor(\"bn4b_branch2a/cond/Merge:0\", shape=(?, 4, 4, 256), dtype=float32)\n",
      "Tensor(\"res4b_branch2b/BiasAdd:0\", shape=(?, 4, 4, 256), dtype=float32)\n",
      "Tensor(\"res4b_branch2c/BiasAdd:0\", shape=(?, 4, 4, 1024), dtype=float32)\n",
      "Tensor(\"activation_31/Relu:0\", shape=(?, 4, 4, 1024), dtype=float32)\n",
      "第一个卷积层有：256块卷积核\n",
      "经过卷积核X的结果 ：(?, 4, 4, 256)\n",
      "Tensor(\"res4c_branch2a/BiasAdd:0\", shape=(?, 4, 4, 256), dtype=float32)\n",
      "经过BatchNormalization的结果 ：Tensor(\"bn4c_branch2a/cond/Merge:0\", shape=(?, 4, 4, 256), dtype=float32)\n",
      "Tensor(\"bn4c_branch2a/cond/Merge:0\", shape=(?, 4, 4, 256), dtype=float32)\n",
      "Tensor(\"res4c_branch2b/BiasAdd:0\", shape=(?, 4, 4, 256), dtype=float32)\n",
      "Tensor(\"res4c_branch2c/BiasAdd:0\", shape=(?, 4, 4, 1024), dtype=float32)\n",
      "Tensor(\"activation_34/Relu:0\", shape=(?, 4, 4, 1024), dtype=float32)\n",
      "第一个卷积层有：256块卷积核\n",
      "经过卷积核X的结果 ：(?, 4, 4, 256)\n",
      "Tensor(\"res4d_branch2a/BiasAdd:0\", shape=(?, 4, 4, 256), dtype=float32)\n",
      "经过BatchNormalization的结果 ：Tensor(\"bn4d_branch2a/cond/Merge:0\", shape=(?, 4, 4, 256), dtype=float32)\n",
      "Tensor(\"bn4d_branch2a/cond/Merge:0\", shape=(?, 4, 4, 256), dtype=float32)\n",
      "Tensor(\"res4d_branch2b/BiasAdd:0\", shape=(?, 4, 4, 256), dtype=float32)\n",
      "Tensor(\"res4d_branch2c/BiasAdd:0\", shape=(?, 4, 4, 1024), dtype=float32)\n",
      "Tensor(\"activation_37/Relu:0\", shape=(?, 4, 4, 1024), dtype=float32)\n",
      "第一个卷积层有：256块卷积核\n",
      "经过卷积核X的结果 ：(?, 4, 4, 256)\n",
      "Tensor(\"res4e_branch2a/BiasAdd:0\", shape=(?, 4, 4, 256), dtype=float32)\n",
      "经过BatchNormalization的结果 ：Tensor(\"bn4e_branch2a/cond/Merge:0\", shape=(?, 4, 4, 256), dtype=float32)\n",
      "Tensor(\"bn4e_branch2a/cond/Merge:0\", shape=(?, 4, 4, 256), dtype=float32)\n",
      "Tensor(\"res4e_branch2b/BiasAdd:0\", shape=(?, 4, 4, 256), dtype=float32)\n",
      "Tensor(\"res4e_branch2c/BiasAdd:0\", shape=(?, 4, 4, 1024), dtype=float32)\n",
      "Tensor(\"activation_40/Relu:0\", shape=(?, 4, 4, 1024), dtype=float32)\n",
      "第一个卷积层有：256块卷积核\n",
      "经过卷积核X的结果 ：(?, 4, 4, 256)\n",
      "Tensor(\"res4f_branch2a/BiasAdd:0\", shape=(?, 4, 4, 256), dtype=float32)\n",
      "经过BatchNormalization的结果 ：Tensor(\"bn4f_branch2a/cond/Merge:0\", shape=(?, 4, 4, 256), dtype=float32)\n",
      "Tensor(\"bn4f_branch2a/cond/Merge:0\", shape=(?, 4, 4, 256), dtype=float32)\n",
      "Tensor(\"res4f_branch2b/BiasAdd:0\", shape=(?, 4, 4, 256), dtype=float32)\n",
      "Tensor(\"res4f_branch2c/BiasAdd:0\", shape=(?, 4, 4, 1024), dtype=float32)\n",
      "X 经过stage4 之后 应该是 1024个通道Tensor(\"activation_43/Relu:0\", shape=(?, 4, 4, 1024), dtype=float32)\n",
      "没有经过卷积操作的 X的维度 Tensor(\"activation_43/Relu:0\", shape=(?, 4, 4, 1024), dtype=float32)\n",
      "经过一次卷积 主路径第一步的维度 Tensor(\"activation_44/Relu:0\", shape=(?, 2, 2, 512), dtype=float32)\n",
      "经过第二次卷积 主路径第二步的维度 Tensor(\"activation_45/Relu:0\", shape=(?, 2, 2, 512), dtype=float32)\n",
      "经过第三次卷积 主路径的第三步的维度为 Tensor(\"bn5a_branch2c/cond/Merge:0\", shape=(?, 2, 2, 2048), dtype=float32)\n",
      "上面路径的卷积的维度 Tensor(\"bn5a_branch1/cond/Merge:0\", shape=(?, 2, 2, 2048), dtype=float32)\n",
      "Tensor(\"activation_46/Relu:0\", shape=(?, 2, 2, 2048), dtype=float32)\n",
      "第一个卷积层有：256块卷积核\n",
      "经过卷积核X的结果 ：(?, 2, 2, 256)\n",
      "Tensor(\"res5b_branch2a/BiasAdd:0\", shape=(?, 2, 2, 256), dtype=float32)\n",
      "经过BatchNormalization的结果 ：Tensor(\"bn5b_branch2a/cond/Merge:0\", shape=(?, 2, 2, 256), dtype=float32)\n",
      "Tensor(\"bn5b_branch2a/cond/Merge:0\", shape=(?, 2, 2, 256), dtype=float32)\n",
      "Tensor(\"res5b_branch2b/BiasAdd:0\", shape=(?, 2, 2, 256), dtype=float32)\n",
      "Tensor(\"res5b_branch2c/BiasAdd:0\", shape=(?, 2, 2, 2048), dtype=float32)\n",
      "Tensor(\"activation_49/Relu:0\", shape=(?, 2, 2, 2048), dtype=float32)\n",
      "第一个卷积层有：256块卷积核\n",
      "经过卷积核X的结果 ：(?, 2, 2, 256)\n",
      "Tensor(\"res5c_branch2a/BiasAdd:0\", shape=(?, 2, 2, 256), dtype=float32)\n",
      "经过BatchNormalization的结果 ：Tensor(\"bn5c_branch2a/cond/Merge:0\", shape=(?, 2, 2, 256), dtype=float32)\n",
      "Tensor(\"bn5c_branch2a/cond/Merge:0\", shape=(?, 2, 2, 256), dtype=float32)\n",
      "Tensor(\"res5c_branch2b/BiasAdd:0\", shape=(?, 2, 2, 256), dtype=float32)\n",
      "Tensor(\"res5c_branch2c/BiasAdd:0\", shape=(?, 2, 2, 2048), dtype=float32)\n",
      "X 经过stage5  之后 应该是 2048个通道Tensor(\"activation_52/Relu:0\", shape=(?, 2, 2, 2048), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "model = ResNet50(input_shape = (64, 64, 3), classes = 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen in the Keras Tutorial Notebook, prior training a model, you need to configure the learning process by compiling the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is now ready to be trained. The only thing you need is a dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the SIGNS Dataset.\n",
    "\n",
    "<img src=\"images/signs_data_kiank.png\" style=\"width:450px;height:250px;\">\n",
    "<caption><center> <u> <font color='purple'> **Figure 6** </u><font color='purple'>  : **SIGNS dataset** </center></caption>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training examples = 1080\n",
      "number of test examples = 120\n",
      "X_train shape: (1080, 64, 64, 3)\n",
      "Y_train shape: (1080, 6)\n",
      "X_test shape: (120, 64, 64, 3)\n",
      "Y_test shape: (120, 6)\n"
     ]
    }
   ],
   "source": [
    "X_train_orig, Y_train_orig, X_test_orig, Y_test_orig, classes = load_dataset()\n",
    "\n",
    "# Normalize image vectors\n",
    "X_train = X_train_orig/255.\n",
    "X_test = X_test_orig/255.\n",
    "\n",
    "# Convert training and test labels to one hot matrices\n",
    "Y_train = convert_to_one_hot(Y_train_orig, 6).T\n",
    "Y_test = convert_to_one_hot(Y_test_orig, 6).T\n",
    "\n",
    "print (\"number of training examples = \" + str(X_train.shape[0]))\n",
    "print (\"number of test examples = \" + str(X_test.shape[0]))\n",
    "print (\"X_train shape: \" + str(X_train.shape))\n",
    "print (\"Y_train shape: \" + str(Y_train.shape))\n",
    "print (\"X_test shape: \" + str(X_test.shape))\n",
    "print (\"Y_test shape: \" + str(Y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cell to train your model on 2 epochs with a batch size of 32. On a CPU it should take you around 5min per epoch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1080/1080 [==============================] - 62s 57ms/step - loss: 2.8591 - acc: 0.2620\n",
      "Epoch 2/20\n",
      "1080/1080 [==============================] - 53s 49ms/step - loss: 2.0505 - acc: 0.4278\n",
      "Epoch 3/20\n",
      "1080/1080 [==============================] - 54s 50ms/step - loss: 1.7355 - acc: 0.5306\n",
      "Epoch 4/20\n",
      "1080/1080 [==============================] - 56s 52ms/step - loss: 1.5762 - acc: 0.5954\n",
      "Epoch 5/20\n",
      "1080/1080 [==============================] - 56s 51ms/step - loss: 1.1756 - acc: 0.7056\n",
      "Epoch 6/20\n",
      "1080/1080 [==============================] - 56s 52ms/step - loss: 1.3859 - acc: 0.7167\n",
      "Epoch 7/20\n",
      "1080/1080 [==============================] - 55s 51ms/step - loss: 1.1106 - acc: 0.7806\n",
      "Epoch 8/20\n",
      "1080/1080 [==============================] - 57s 53ms/step - loss: 1.0233 - acc: 0.8380\n",
      "Epoch 9/20\n",
      "1080/1080 [==============================] - 56s 51ms/step - loss: 0.7111 - acc: 0.8731\n",
      "Epoch 10/20\n",
      "1080/1080 [==============================] - 54s 50ms/step - loss: 0.9185 - acc: 0.7898\n",
      "Epoch 11/20\n",
      "1080/1080 [==============================] - 53s 50ms/step - loss: 0.6180 - acc: 0.8519\n",
      "Epoch 12/20\n",
      "1080/1080 [==============================] - 55s 51ms/step - loss: 0.8078 - acc: 0.7389\n",
      "Epoch 13/20\n",
      "1080/1080 [==============================] - 53s 49ms/step - loss: 0.4632 - acc: 0.8537\n",
      "Epoch 14/20\n",
      "1080/1080 [==============================] - 53s 49ms/step - loss: 0.8092 - acc: 0.7907\n",
      "Epoch 15/20\n",
      "1080/1080 [==============================] - 52s 48ms/step - loss: 0.5287 - acc: 0.8454\n",
      "Epoch 16/20\n",
      "1080/1080 [==============================] - 52s 48ms/step - loss: 0.2669 - acc: 0.9352\n",
      "Epoch 17/20\n",
      "1080/1080 [==============================] - 52s 48ms/step - loss: 0.1938 - acc: 0.9556\n",
      "Epoch 18/20\n",
      "1080/1080 [==============================] - 52s 49ms/step - loss: 0.1373 - acc: 0.9574\n",
      "Epoch 19/20\n",
      "1080/1080 [==============================] - 52s 48ms/step - loss: 0.3583 - acc: 0.9259\n",
      "Epoch 20/20\n",
      "1080/1080 [==============================] - 53s 49ms/step - loss: 0.2015 - acc: 0.9491\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x181fb1ee48>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, epochs = 20, batch_size = 32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**:\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            ** Epoch 1/2**\n",
    "        </td>\n",
    "        <td>\n",
    "           loss: between 1 and 5, acc: between 0.2 and 0.5, although your results can be different from ours.\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>\n",
    "            ** Epoch 2/2**\n",
    "        </td>\n",
    "        <td>\n",
    "           loss: between 1 and 5, acc: between 0.2 and 0.5, you should see your loss decreasing and the accuracy increasing.\n",
    "        </td>\n",
    "    </tr>\n",
    "\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how this model (trained on only two epochs) performs on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 6s 49ms/step\n",
      "Loss = 1.8349506696065268\n",
      "Test Accuracy = 0.16666666716337203\n"
     ]
    }
   ],
   "source": [
    "preds = model.evaluate(X_test, Y_test)\n",
    "print (\"Loss = \" + str(preds[0]))\n",
    "print (\"Test Accuracy = \" + str(preds[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**:\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            **Test Accuracy**\n",
    "        </td>\n",
    "        <td>\n",
    "           between 0.16 and 0.25\n",
    "        </td>\n",
    "    </tr>\n",
    "\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the purpose of this assignment, we've asked you to train the model only for two epochs. You can see that it achieves poor performances. Please go ahead and submit your assignment; to check correctness, the online grader will run your code only for a small number of epochs as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of the trained model (NOT PROVIDED)\n",
    "After you have finished this official (graded) part of this assignment, you can also optionally train the ResNet for more iterations, if you want. We get a lot better performance when we train for ~20 epochs, but this will take more than an hour when training on a CPU. \n",
    "\n",
    "Using a GPU, we've trained our own ResNet50 model's weights on the SIGNS dataset. You can load and run our trained model on the test set in the cells below. It may take ≈1min to load the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = load_model('ResNet50.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "preds = model.evaluate(X_test, Y_test)\n",
    "print (\"Loss = \" + str(preds[0]))\n",
    "print (\"Test Accuracy = \" + str(preds[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ResNet50 is a powerful model for image classification when it is trained for an adequate number of iterations. We hope you can use what you've learnt and apply it to your own classification problem to perform state-of-the-art accuracy.\n",
    "\n",
    "Congratulations on finishing this assignment! You've now implemented a state-of-the-art image classification system! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - Test on your own image (Optional/Ungraded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you wish, you can also take a picture of your own hand and see the output of the model. To do this:\n",
    "    1. Click on \"File\" in the upper bar of this notebook, then click \"Open\" to go on your Coursera Hub.\n",
    "    2. Add your image to this Jupyter Notebook's directory, in the \"images\" folder\n",
    "    3. Write your image's name in the following code\n",
    "    4. Run the code and check if the algorithm is right! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_path = 'images/my_image.jpg'\n",
    "img = image.load_img(img_path, target_size=(64, 64))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)\n",
    "print('Input image shape:', x.shape)\n",
    "my_image = scipy.misc.imread(img_path)\n",
    "imshow(my_image)\n",
    "print(\"class prediction vector [p(0), p(1), p(2), p(3), p(4), p(5)] = \")\n",
    "print(model.predict(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also print a summary of your model by running the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, run the code below to visualize your ResNet50. You can also download a .png picture of your model by going to \"File -> Open...-> model.png\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_model(model, to_file='model.png')\n",
    "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>\n",
    "**What you should remember:**\n",
    "- Very deep \"plain\" networks don't work in practice because they are hard to train due to vanishing gradients.  \n",
    "- The skip-connections help to address the Vanishing Gradient problem. They also make it easy for a ResNet block to learn an identity function. \n",
    "- There are two main type of blocks: The identity block and the convolutional block. \n",
    "- Very deep Residual Networks are built by stacking these blocks together."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References \n",
    "\n",
    "This notebook presents the ResNet algorithm due to He et al. (2015). The implementation here also took significant inspiration and follows the structure given in the github repository of Francois Chollet: \n",
    "\n",
    "- Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun - [Deep Residual Learning for Image Recognition (2015)](https://arxiv.org/abs/1512.03385)\n",
    "- Francois Chollet's github repository: https://github.com/fchollet/deep-learning-models/blob/master/resnet50.py\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "coursera": {
   "course_slug": "convolutional-neural-networks",
   "graded_item_id": "OEpi5",
   "launcher_item_id": "jK9EQ"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
